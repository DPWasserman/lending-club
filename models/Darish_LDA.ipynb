{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('python3.8.8': conda)",
   "metadata": {
    "interpreter": {
     "hash": "36bf2d6b56364c7c2f7e9b6c8cc450b46f575ae98c5d77929445b306ba8812fb"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the packages that we need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "import coiled\n",
    "import joblib\n",
    "pd.set_option('display.max_rows', 500)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dask_ml.preprocessing import Categorizer, DummyEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NAs\n",
    "def remove_na(dd):\n",
    "    \"\"\"\n",
    "    This function removes NAs and outliers in annual_inc\n",
    "\n",
    "    params: dd - a dask dataframe\n",
    "    returns: dd - a dask dataframe with only grades we need\n",
    "    \"\"\"\n",
    "    dd = dd.dropna(subset=['annual_inc',\n",
    "                            'dti',\n",
    "                            'pub_rec',\n",
    "                            'pub_rec_bankruptcies',\n",
    "                            'int_rate',\n",
    "                            'loan_amnt',\n",
    "                            'grade',\n",
    "                            'sub_grade',\n",
    "                            'verification_status',\n",
    "                            'term'\n",
    "                            ])\n",
    "    dd.annual_inc = dd.annual_inc[dd.annual_inc < 2e7]\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter out grades F and G\n",
    "def filter_grade(dd):\n",
    "    \"\"\"\n",
    "    This function filters out functions F and G\n",
    "\n",
    "    params: dd - a dask dataframe\n",
    "    returns: dd - a dask dataframe with only grades we need\n",
    "    \"\"\"\n",
    "    dd = dd[dd['grade'].isin(['A', 'B', 'C', 'D', 'E'])]\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_loan_status(dd):\n",
    "    dd = dd[dd['loan_status'].isin(['Charged Off','Fully Paid'])]\n",
    "\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineer days_since_earliest_credit\n",
    "def get_days_first_credit(dd):\n",
    "    \"\"\"\n",
    "    This function adds a new column that holds info on how many days has it been since first credit to loan issuance.\n",
    "\n",
    "    params: dd - a dask dataframe\n",
    "    returns: dd - a dask dataframe with the new column added\n",
    "    \"\"\"\n",
    "    dd['days_since_first_credit'] = (dd['issue_d'] - dd['earliest_cr_line']).dt.days\n",
    "    \n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean emp_length\n",
    "def clean_emp_length(dd):\n",
    "    \"\"\"\n",
    "    This function cleans emp_length\n",
    "\n",
    "    params: dd - a dask dataframe\n",
    "    returns: dd - a dask dataframe with the new column added\n",
    "    \"\"\"\n",
    "    dd.emp_length = dd.emp_length.replace(to_replace='< 1 year', value='0')\n",
    "    dd.emp_length = dd.emp_length.str.strip('<+ years')\n",
    "    dd.emp_length = dd.emp_length.fillna('-1')\n",
    "    dd.emp_length = dd.emp_length.astype(int)\n",
    "\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to separate data by term\n",
    "def separate_by_term(dd):\n",
    "    dd.term = dd.term.str.strip(' months').astype(int)\n",
    "     \n",
    "    df_3 = dd[dd.term == 36]\n",
    "    df_5 = dd[dd.term == 60]\n",
    "\n",
    "    df_3 = df_3[df_3['issue_d'].dt.year <= 2015]\n",
    "    df_5 = df_5[df_5['issue_d'].dt.year <= 2013]\n",
    "\n",
    "    return df_3,df_5  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to select all the features that we want\n",
    "def select_features(dd):\n",
    "    \"\"\"\n",
    "    This function selects only the features that we want for future modelling\n",
    "\n",
    "    params: dd - a dask dataframe\n",
    "    returns: dd - a dask dataframe with only the features selected\n",
    "\n",
    "    Notes:\n",
    "    1. We are not selecting grade since the information is already present in sub_grade\n",
    "    2. We are not selecting open_acc since we believe that feature is updated throughout time\n",
    "    3. Emp_title is dropped since we cannot clean it\n",
    "    4. Zip code is dropped since there is too many and State would give enough information\n",
    "    \"\"\"\n",
    "    dd = dd[[\n",
    "            'addr_state', # Need to dummify\n",
    "            'annual_inc',\n",
    "            'disbursement_method', # Need to binarize\n",
    "            'dti',\n",
    "            'emp_length', # Need to convert to number and add NAs\n",
    "            'fico_range_high', \n",
    "            'fico_range_low',\n",
    "            'home_ownership', # Need to dummify\n",
    "            'initial_list_status', # Need to dummify (binarize)\n",
    "            'installment',\n",
    "            'int_rate',\n",
    "            'loan_amnt', \n",
    "            'pub_rec', \n",
    "            'pub_rec_bankruptcies',\n",
    "            'purpose', # Need to dummify\n",
    "            'sub_grade', # Need to dummify or be ordinal encoded\n",
    "            'verification_status',\n",
    "            'loan_status' # Need to dummify\n",
    "    ]]\n",
    "\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical(dd):\n",
    "    ce = Categorizer(columns=['addr_state', 'disbursement_method', 'emp_length', 'home_ownership', 'initial_list_status', 'purpose', 'verification_status', 'sub_grade'])\n",
    "    dd = ce.fit_transform(dd)\n",
    "    de = DummyEncoder(columns=['addr_state', 'disbursement_method', 'emp_length', 'home_ownership', 'initial_list_status', 'purpose', 'verification_status', 'sub_grade'])\n",
    "    dd = de.fit_transform(dd)\n",
    "\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(dd):\n",
    "    scaler = StandardScaler()\n",
    "    dd = scaler.fit_transform(dd)\n",
    "\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Output()",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1ef050a3e17e4e2a8035336a43ccd214"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<rich.jupyter.JupyterRenderable at 0x7fdde51a4100>",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Using existing cluster: <span style=\"color: #008000; text-decoration-color: #008000\">'DarishSakeesing-bc650b6e-1'</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<rich.jupyter.JupyterRenderable at 0x7fdde5409a90>",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dashboard: http://ec2-3-142-95-126.us-east-2.compute.amazonaws.com:8787\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# cluster = coiled.Cluster(n_workers=10)\n",
    "cluster = coiled.Cluster(name='DarishSakeesing-bc650b6e-1')\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "print('Dashboard:', client.dashboard_link)\n",
    "\n",
    "\n",
    "\n",
    "raw_data = dd.read_csv(\n",
    "    \"s3://lending-club/accepted_2007_to_2018Q4.csv\",\n",
    "    dtype={'desc': 'object', \n",
    "            'id': 'object',\n",
    "            'sec_app_earliest_cr_line': 'object'}, \n",
    "    parse_dates = ['issue_d','earliest_cr_line'],\n",
    "    low_memory=False,\n",
    "    storage_options={\"anon\": True},\n",
    "    blocksize=\"16 MiB\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = remove_na(raw_data)\n",
    "raw_data = filter_grade(raw_data)\n",
    "raw_data = filter_loan_status(raw_data)\n",
    "raw_data = get_days_first_credit(raw_data)\n",
    "raw_data = clean_emp_length(raw_data)\n",
    "df_3, df_5 = separate_by_term(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = select_features(df_3)\n",
    "df_5 = select_features(df_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_3 = df_3.pop('loan_status')\n",
    "y_5 = df_5.pop('loan_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = encode_categorical(df_3)\n",
    "df_5 = encode_categorical(df_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = scale_features(df_3)\n",
    "df_5 = scale_features(df_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_3 = LabelEncoder()\n",
    "y_3 = le_3.fit_transform(y_3)\n",
    "le_5 = LabelEncoder()\n",
    "y_5 = le_5.fit_transform(y_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with joblib.parallel_backend('dask', n_jobs=-1):\n",
    "    X_3_train, X_3_test, y_3_train, y_3_test = train_test_split(df_3.compute(), y_3.compute(), test_size=0.2, shuffle=True)\n",
    "    X_5_train, X_5_test, y_5_train, y_5_test = train_test_split(df_5.compute(), y_5.compute(), test_size=0.2, shuffle=True)"
   ]
  },
  {
   "source": [
    "# Null Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1    423099\n",
       "0     67397\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "pd.Series(y_3_train).value_counts()"
   ]
  },
  {
   "source": [
    "# Linear Discriminant Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constucting Priors List\n",
    "priors = []\n",
    "for x in range(0, 101, 1):\n",
    "    priors.append([x/100, (100-x)/100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Initialized estimators\n",
      "Initialized grid\n",
      "Entered parallel backend\n",
      "Fitting 3 folds for each of 101 candidates, totalling 303 fits\n",
      "Finished 3, Starting 5\n",
      "Fitting 3 folds for each of 101 candidates, totalling 303 fits\n"
     ]
    }
   ],
   "source": [
    "params = {'priors': priors}\n",
    "lda_3 = LinearDiscriminantAnalysis()\n",
    "lda_5 = LinearDiscriminantAnalysis()\n",
    "print('Initialized estimators')\n",
    "\n",
    "grid_search_3 = GridSearchCV(estimator=lda_3, param_grid=params, scoring='balanced_accuracy', n_jobs=-1, cv=3, verbose=5)\n",
    "grid_search_5 = GridSearchCV(estimator=lda_5, param_grid=params, scoring='balanced_accuracy', n_jobs=-1, cv=3, verbose=5)\n",
    "print('Initialized grid')\n",
    "\n",
    "with joblib.parallel_backend('dask', n_jobs=-1, scatter=[X_3_train, y_3_train, X_5_train, y_5_train]):\n",
    "    print('Entered parallel backend')\n",
    "    grid_search_3.fit(X_3_train, y_3_train)\n",
    "    print('Finished 3, Starting 5')\n",
    "    grid_search_5.fit(X_5_train, y_5_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_3 = LinearDiscriminantAnalysis(priors=grid_search_3.best_params_['priors'])\n",
    "lda_3.fit(X_3_train, y_3_train)\n",
    "cm_3 = confusion_matrix(y_3_test, lda_3.predict(X_3_test), labels=[0,1])\n",
    "cm_3_df = pd.DataFrame(cm_3, columns=[f'Pred_{label}' for label in le_3.classes_.compute()], index= [f'True_{label}' for label in le_3.classes_.compute()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_5 = LinearDiscriminantAnalysis(priors=grid_search_5.best_params_['priors'])\n",
    "lda_5.fit(X_5_train, y_5_train)\n",
    "cm_5 = confusion_matrix(y_5_test, lda_5.predict(X_5_test), labels=[0,1])\n",
    "cm_5_df = pd.DataFrame(cm_5, columns=[f'Pred_{label}' for label in le_5.classes_.compute()], index= [f'True_{label}' for label in le_5.classes_.compute()])"
   ]
  },
  {
   "source": [
    "## Confusion Matrix for LDA 3-YEAR Loans"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  Pred_Charged Off  Pred_Fully Paid\n",
       "True_Charged Off             10295             6544\n",
       "True_Fully Paid              38134            67651"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pred_Charged Off</th>\n      <th>Pred_Fully Paid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>True_Charged Off</th>\n      <td>10295</td>\n      <td>6544</td>\n    </tr>\n    <tr>\n      <th>True_Fully Paid</th>\n      <td>38134</td>\n      <td>67651</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "cm_3_df"
   ]
  },
  {
   "source": [
    "## Confusion Matrix for LDA 5-YEAR Loans"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "cm_5_df"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  Pred_Charged Off  Pred_Fully Paid\n",
       "True_Charged Off              1167             1023\n",
       "True_Fully Paid               2705             4662"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pred_Charged Off</th>\n      <th>Pred_Fully Paid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>True_Charged Off</th>\n      <td>1167</td>\n      <td>1023</td>\n    </tr>\n    <tr>\n      <th>True_Fully Paid</th>\n      <td>2705</td>\n      <td>4662</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ]
  },
  {
   "source": [
    "# Random Forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Initialized estimators\n",
      "Initialzed Grid\n",
      "Entered parallel backend\n",
      "Fitting 3 folds for each of 4320 candidates, totalling 12960 fits\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-5c0f2423ddeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dask'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_3_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_3_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_5_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_5_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Entered parallel backend'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mrf_grid_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_3_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_3_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Finished 3, Starting 5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mrf_grid_5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_5_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_5_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python3.8.8/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python3.8.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python3.8.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python3.8.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python3.8.8/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python3.8.8/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python3.8.8/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python3.8.8/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "forest_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "rfc_3 = RandomForestClassifier()\n",
    "rfc_5 = RandomForestClassifier()\n",
    "print('Initialized estimators')\n",
    "\n",
    "rf_grid_3 = GridSearchCV(estimator = rfc_3, param_grid = forest_grid, cv = 3, verbose=3, n_jobs = -1)\n",
    "rf_grid_5 = GridSearchCV(estimator = rfc_5, param_grid = forest_grid, cv = 3, verbose=3, n_jobs = -1)\n",
    "print('Initialzed Grid')\n",
    "\n",
    "\n",
    "\n",
    "with joblib.parallel_backend('dask', n_jobs=-1, scatter=[X_3_train, y_3_train, X_5_train, y_5_train]):\n",
    "    print('Entered parallel backend')\n",
    "    rf_grid_3.fit(X_3_train, y_3_train)\n",
    "    print('Finished 3, Starting 5')\n",
    "    rf_grid_5.fit(X_5_train, y_5_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_3 = rf_grid_3.best_estimator_\n",
    "rfc_3.fit(X_3_train, y_3_train)\n",
    "cm_3 = confusion_matrix(y_3_test, rfc_3.predict(X_3_test), labels=[0,1])\n",
    "cm_3_df = pd.DataFrame(cm_3, columns=[f'Pred_{label}' for label in le_3.classes_.compute()], index= [f'True_{label}' for label in le_3.classes_.compute()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_5 = rf_grid_5.best_estimator_\n",
    "rfc_5.fit(X_5_train, y_5_train)\n",
    "cm_5 = confusion_matrix(y_5_test, rfc_5.predict(X_5_test), labels=[0,1])\n",
    "cm_5_df = pd.DataFrame(cm_5, columns=[f'Pred_{label}' for label in le_5.classes_.compute()], index= [f'True_{label}' for label in le_5.classes_.compute()])"
   ]
  }
 ]
}