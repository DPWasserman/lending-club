{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('python3.8.8': conda)",
   "metadata": {
    "interpreter": {
     "hash": "36bf2d6b56364c7c2f7e9b6c8cc450b46f575ae98c5d77929445b306ba8812fb"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the packages that we need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "import coiled\n",
    "import joblib\n",
    "from joblib import dump, load\n",
    "pd.set_option('display.max_rows', 2000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dask_ml.preprocessing import Categorizer, DummyEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NAs\n",
    "def remove_na(dd):\n",
    "    \"\"\"\n",
    "    This function removes NAs and outliers in annual_inc\n",
    "\n",
    "    params: dd - a dask dataframe\n",
    "    returns: dd - a dask dataframe with only grades we need\n",
    "    \"\"\"\n",
    "    dd = dd.dropna(subset=['annual_inc',\n",
    "                            'dti',\n",
    "                            'pub_rec',\n",
    "                            'pub_rec_bankruptcies',\n",
    "                            'int_rate',\n",
    "                            'loan_amnt',\n",
    "                            'grade',\n",
    "                            'sub_grade',\n",
    "                            'verification_status',\n",
    "                            'term'\n",
    "                            ])\n",
    "    \n",
    "    dd.annual_inc = dd.annual_inc[dd.annual_inc < 2e7]\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter out grades F and G\n",
    "def filter_grade(dd):\n",
    "    \"\"\"\n",
    "    This function filters out functions F and G\n",
    "\n",
    "    params: dd - a dask dataframe\n",
    "    returns: dd - a dask dataframe with only grades we need\n",
    "    \"\"\"\n",
    "    dd = dd[dd['grade'].isin(['A', 'B', 'C', 'D', 'E'])]\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_loan_status(dd):\n",
    "    dd = dd[dd['loan_status'].isin(['Charged Off','Fully Paid'])]\n",
    "\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineer days_since_earliest_credit\n",
    "def get_days_first_credit(dd):\n",
    "    \"\"\"\n",
    "    This function adds a new column that holds info on how many days has it been since first credit to loan issuance.\n",
    "\n",
    "    params: dd - a dask dataframe\n",
    "    returns: dd - a dask dataframe with the new column added\n",
    "    \"\"\"\n",
    "    dd['days_since_first_credit'] = (dd['issue_d'] - dd['earliest_cr_line']).dt.days\n",
    "    \n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean emp_length\n",
    "def clean_emp_length(dd):\n",
    "    \"\"\"\n",
    "    This function cleans emp_length\n",
    "\n",
    "    params: dd - a dask dataframe\n",
    "    returns: dd - a dask dataframe with the new column added\n",
    "    \"\"\"\n",
    "    dd.emp_length = dd.emp_length.replace(to_replace='< 1 year', value='0')\n",
    "    dd.emp_length = dd.emp_length.str.strip('<+ years')\n",
    "    dd.emp_length = dd.emp_length.fillna('-1')\n",
    "    dd.emp_length = dd.emp_length.astype(int)\n",
    "\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to separate data by term\n",
    "def separate_by_term(dd):\n",
    "    dd.term = dd.term.str.strip(' months').astype(int)\n",
    "     \n",
    "    df_3 = dd[dd.term == 36]\n",
    "    df_5 = dd[dd.term == 60]\n",
    "\n",
    "    df_3 = df_3[df_3['issue_d'].dt.year <= 2015]\n",
    "    df_5 = df_5[df_5['issue_d'].dt.year <= 2013]\n",
    "\n",
    "    return df_3,df_5  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to select all the features that we want\n",
    "def select_features(dd): \n",
    "    \"\"\"\n",
    "    This function selects only the features that we want for future modelling\n",
    "\n",
    "    params: dd - a dask dataframe\n",
    "    returns: dd - a dask dataframe with only the features selected\n",
    "\n",
    "    Notes:\n",
    "    1. We are not selecting grade since the information is already present in sub_grade\n",
    "    2. We are not selecting open_acc since we believe that feature is updated throughout time\n",
    "    3. Emp_title is dropped since we cannot clean it\n",
    "    4. Zip code is dropped since there is too many and State would give enough information\n",
    "    \"\"\"\n",
    "    dd = dd[[\n",
    "            'addr_state', # Need to dummify\n",
    "            'annual_inc',\n",
    "            'disbursement_method', # Need to binarize\n",
    "            'dti',\n",
    "            'emp_length', # Need to convert to number and add NAs\n",
    "            'fico_range_high', \n",
    "            'fico_range_low',\n",
    "            'home_ownership', # Need to dummify\n",
    "            'initial_list_status', # Need to dummify (binarize)\n",
    "            'installment',\n",
    "            'int_rate',\n",
    "            'loan_amnt', \n",
    "            'pub_rec', \n",
    "            'pub_rec_bankruptcies',\n",
    "            'purpose', # Need to dummify\n",
    "            'sub_grade', # Need to dummify or be ordinal encoded\n",
    "            'verification_status',\n",
    "            'loan_status' # Need to dummify\n",
    "    ]]\n",
    "\n",
    "    return dd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical(dd):\n",
    "    # ce = Categorizer(columns=['addr_state', 'disbursement_method', 'emp_length', 'home_ownership', 'initial_list_status', 'purpose', 'verification_status', 'sub_grade'])\n",
    "    # dd = ce.fit_transform(dd)\n",
    "    # de = DummyEncoder(columns=['addr_state', 'disbursement_method', 'emp_length', 'home_ownership', 'initial_list_status', 'purpose', 'verification_status', 'sub_grade'])\n",
    "    # dd = de.fit_transform(dd)\n",
    "\n",
    "    ce = Categorizer(columns=['addr_state', 'disbursement_method', 'emp_length', 'home_ownership', 'initial_list_status', 'purpose', 'verification_status'])\n",
    "    dd = ce.fit_transform(dd)\n",
    "    de = DummyEncoder(columns=['addr_state', 'disbursement_method', 'emp_length', 'home_ownership', 'initial_list_status', 'purpose', 'verification_status'])\n",
    "    dd = de.fit_transform(dd)\n",
    "\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(dd):\n",
    "    scaler = StandardScaler()\n",
    "    dd = scaler.fit_transform(dd)\n",
    "\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import distributed\n",
    "distributed.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = coiled.Cluster(n_workers=10)\n",
    "# cluster = coiled.Cluster(name='DarishSakeesing-855fcb7f-8')\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "print('Dashboard:', client.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = dd.read_csv(\n",
    "    \"s3://lending-club2/accepted_2007_to_2018Q4.csv\",\n",
    "    dtype={'desc': 'object', \n",
    "            'id': 'object',\n",
    "            'sec_app_earliest_cr_line': 'object'}, \n",
    "    parse_dates = ['issue_d','earliest_cr_line'],\n",
    "    low_memory=False,\n",
    "    storage_options={\"anon\": True},\n",
    "    blocksize=\"16 MiB\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('0')\n",
    "raw_data = remove_na(raw_data)\n",
    "print('1')\n",
    "raw_data = filter_grade(raw_data)\n",
    "print('2')\n",
    "raw_data = filter_loan_status(raw_data)\n",
    "print('3')\n",
    "raw_data = get_days_first_credit(raw_data)\n",
    "print('4')\n",
    "raw_data = clean_emp_length(raw_data)\n",
    "print('5')\n",
    "df_3, df_5 = separate_by_term(raw_data)\n",
    "print('6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = select_features(df_3)\n",
    "df_5 = select_features(df_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df_3 = df_3.compute()\n",
    "save_df_5 = df_5.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df_3.reset_index(inplace=True, drop=True)\n",
    "save_df_5.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_3 = df_3.pop('loan_status')\n",
    "y_5 = df_5.pop('loan_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ce_3 = Categorizer(columns=['addr_state', 'disbursement_method', 'emp_length', 'home_ownership', 'initial_list_status', 'purpose', 'verification_status', 'sub_grade'])\n",
    "# df_3 = ce_3.fit_transform(df_3)\n",
    "# de_3 = DummyEncoder(columns=['addr_state', 'disbursement_method', 'emp_length', 'home_ownership', 'initial_list_status', 'purpose', 'verification_status', 'sub_grade'])\n",
    "# df_3 = de_3.fit_transform(df_3)\n",
    "\n",
    "# ce_5 = Categorizer(columns=['addr_state', 'disbursement_method', 'emp_length', 'home_ownership', 'initial_list_status', 'purpose', 'verification_status', 'sub_grade'])\n",
    "# df_5 = ce_3.fit_transform(df_5)\n",
    "# de_5 = DummyEncoder(columns=['addr_state', 'disbursement_method', 'emp_length', 'home_ownership', 'initial_list_status', 'purpose', 'verification_status', 'sub_grade'])\n",
    "# df_5 = de_3.fit_transform(df_5)\n",
    "\n",
    "ce_3 = Categorizer(columns=['addr_state', 'disbursement_method', 'emp_length', 'home_ownership', 'initial_list_status', 'purpose', 'verification_status'])\n",
    "df_3 = ce_3.fit_transform(df_3)\n",
    "de_3 = DummyEncoder(columns=['addr_state', 'disbursement_method', 'emp_length', 'home_ownership', 'initial_list_status', 'purpose', 'verification_status'])\n",
    "df_3 = de_3.fit_transform(df_3)\n",
    "\n",
    "ce_5 = Categorizer(columns=['addr_state', 'disbursement_method', 'emp_length', 'home_ownership', 'initial_list_status', 'purpose', 'verification_status'])\n",
    "df_5 = ce_3.fit_transform(df_5)\n",
    "de_5 = DummyEncoder(columns=['addr_state', 'disbursement_method', 'emp_length', 'home_ownership', 'initial_list_status', 'purpose', 'verification_status'])\n",
    "df_5 = de_3.fit_transform(df_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_3 = encode_categorical(df_3)\n",
    "# df_5 = encode_categorical(df_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_3 = scale_features(df_3)\n",
    "# df_5 = scale_features(df_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_3 = StandardScaler()\n",
    "df_3 = sc_3.fit_transform(df_3)\n",
    "sc_5 = StandardScaler()\n",
    "sc_5 = sc_5.fit_transform(df_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_3 = LabelEncoder()\n",
    "y_3 = le_3.fit_transform(y_3)\n",
    "le_5 = LabelEncoder()\n",
    "y_5 = le_5.fit_transform(y_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = df_3.compute().reset_index(drop=True)\n",
    "df_5 = df_5.compute().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with joblib.parallel_backend('dask', n_jobs=-1):\n",
    "    X_3_train, X_3_test, y_3_train, y_3_test = train_test_split(df_3, y_3.compute(), test_size=0.2, shuffle=True)\n",
    "    X_5_train, X_5_test, y_5_train, y_5_test = train_test_split(df_5, y_5.compute(), test_size=0.2, shuffle=True)"
   ]
  },
  {
   "source": [
    "# Null Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The models we will come up detects *charged_off* as a negative class and *fully_paid* as positive class. \n",
    "\n",
    "Let's see the performance of a model that classifies everything as positive, i.e., the null model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 3-YEAR NULL Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_3_pred_null = np.ones(len(y_3_test)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_3_null = confusion_matrix(y_3_test, y_3_pred_null)\n",
    "cm_3_null_df = pd.DataFrame(cm_3_null, columns=[f'Pred_{label}' for label in le_3.classes_.compute()], index= [f'True_{label}' for label in le_3.classes_.compute()])\n",
    "cm_3_null_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_full_paid = cm_3_null_df.iloc[1, 1] / (cm_3_null_df.iloc[1, 1] + cm_3_null_df.iloc[0, 1])\n",
    "print('Precision of Fully Paid (Null Model):\\n' + str(precision_full_paid))\n"
   ]
  },
  {
   "source": [
    "## 5-YEAR NULL Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_5_pred_null = np.ones(len(y_5_test)).astype(int)\n",
    "cm_5_null = confusion_matrix(y_5_test, y_5_pred_null)\n",
    "cm_5_null_df = pd.DataFrame(cm_5_null, columns=[f'Pred_{label}' for label in le_5.classes_.compute()], index= [f'True_{label}' for label in le_5.classes_.compute()])\n",
    "cm_5_null_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_full_paid = cm_5_null_df.iloc[1, 1] / (cm_5_null_df.iloc[1, 1] + cm_5_null_df.iloc[0, 1])\n",
    "print('Precision of Fully Paid (Null Model):\\n' + str(precision_full_paid))"
   ]
  },
  {
   "source": [
    "# Linear Discriminant Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## ROC_AUC Metric"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constucting Priors List\n",
    "priors = []\n",
    "for x in range(0, 101, 1):\n",
    "    priors.append([x/100, (100-x)/100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_scoring(estimator, X, y):\n",
    "    return roc_auc_score(y, estimator.predict(X), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'priors': priors}\n",
    "lda_3 = LinearDiscriminantAnalysis()\n",
    "lda_5 = LinearDiscriminantAnalysis()\n",
    "print('Initialized estimators')\n",
    "\n",
    "\n",
    "grid_search_3_roc = GridSearchCV(estimator=lda_3, param_grid=params, scoring=custom_scoring, n_jobs=-1, cv=3, verbose=5)\n",
    "grid_search_5_roc = GridSearchCV(estimator=lda_5, param_grid=params, scoring=custom_scoring, n_jobs=-1, cv=3, verbose=5)\n",
    "print('Initialized grid')\n",
    "\n",
    "with joblib.parallel_backend('dask', n_jobs=-1, scatter=[X_3_train, y_3_train, X_5_train, y_5_train]):\n",
    "    print('Entered parallel backend')\n",
    "    grid_search_3_roc.fit(X_3_train, y_3_train)\n",
    "    print('Finished 3, Starting 5')\n",
    "    grid_search_5_roc.fit(X_5_train, y_5_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_3 = LinearDiscriminantAnalysis(priors=grid_search_3_roc.best_params_['priors'])\n",
    "lda_3.fit(X_3_train, y_3_train)\n",
    "cm_3 = confusion_matrix(y_3_test, lda_3.predict(X_3_test), labels=[0,1])\n",
    "cm_3_df = pd.DataFrame(cm_3, columns=[f'Pred_{label}' for label in le_3.classes_.compute()], index= [f'True_{label}' for label in le_3.classes_.compute()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_5 = LinearDiscriminantAnalysis(priors=grid_search_5_roc.best_params_['priors'])\n",
    "lda_5.fit(X_5_train, y_5_train)\n",
    "cm_5 = confusion_matrix(y_5_test, lda_5.predict(X_5_test), labels=[0,1])\n",
    "cm_5_df = pd.DataFrame(cm_5, columns=[f'Pred_{label}' for label in le_5.classes_.compute()], index= [f'True_{label}' for label in le_5.classes_.compute()])"
   ]
  },
  {
   "source": [
    "## Confusion Matrix for LDA 3-YEAR Loans (ROC_AUC)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_3_df"
   ]
  },
  {
   "source": [
    "## Confusion Matrix for LDA 5-YEAR Loans (ROC_AUC)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "cm_5_df"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "# dump(lda_3, 'lda_3_ROC.joblib')\n",
    "# dump(lda_5, 'lda_5_ROC.joblib')"
   ]
  },
  {
   "source": [
    "## Balanced Accuracy Metric"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'priors': priors}\n",
    "lda_3 = LinearDiscriminantAnalysis()\n",
    "lda_5 = LinearDiscriminantAnalysis()\n",
    "print('Initialized estimators')\n",
    "\n",
    "\n",
    "grid_search_3 = GridSearchCV(estimator=lda_3, param_grid=params, scoring='balanced_accuracy', n_jobs=-1, cv=3, verbose=5)\n",
    "grid_search_5 = GridSearchCV(estimator=lda_5, param_grid=params, scoring='balanced_accuracy', n_jobs=-1, cv=3, verbose=5)\n",
    "print('Initialized grid')\n",
    "\n",
    "with joblib.parallel_backend('dask', n_jobs=-1, scatter=[X_3_train, y_3_train, X_5_train, y_5_train]):\n",
    "    print('Entered parallel backend')\n",
    "    grid_search_3.fit(X_3_train, y_3_train)\n",
    "    print('Finished 3, Starting 5')\n",
    "    grid_search_5.fit(X_5_train, y_5_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_3 = LinearDiscriminantAnalysis(priors=grid_search_3.best_params_['priors'])\n",
    "lda_3.fit(X_3_train, y_3_train)\n",
    "cm_3 = confusion_matrix(y_3_test, lda_3.predict(X_3_test), labels=[0,1])\n",
    "cm_3_df = pd.DataFrame(cm_3, columns=[f'Pred_{label}' for label in le_3.classes_.compute()], index= [f'True_{label}' for label in le_3.classes_.compute()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_5 = LinearDiscriminantAnalysis(priors=grid_search_5.best_params_['priors'])\n",
    "lda_5.fit(X_5_train, y_5_train)\n",
    "cm_5 = confusion_matrix(y_5_test, lda_5.predict(X_5_test), labels=[0,1])\n",
    "cm_5_df = pd.DataFrame(cm_5, columns=[f'Pred_{label}' for label in le_5.classes_.compute()], index= [f'True_{label}' for label in le_5.classes_.compute()])"
   ]
  },
  {
   "source": [
    "## Confusion Matrix for LDA 3-YEAR Loans (Balanced_Accuracy)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_3_df"
   ]
  },
  {
   "source": [
    "## Confusion Matrix for LDA 5-YEAR Loans (Balanced_Accuracy)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_5_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_3_roc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "dump(lda_3, 'lda_3_balanced.joblib')\n",
    "dump(lda_5, 'lda_5_balanced.joblib')"
   ]
  },
  {
   "source": [
    "# INVESTIGATING ERRORS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_3 = load('lda_3_balanced.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive = []\n",
    "false_negative = []\n",
    "true_positive = []\n",
    "true_negative = []\n",
    "predictions = lda_3.predict(X_3_test)\n",
    "for index, pred, lbl in zip(X_3_test.index, predictions, y_3_test):\n",
    "    if pred != lbl:\n",
    "        if pred == 1 and lbl == 0:\n",
    "            false_positive.append(index)\n",
    "        else:\n",
    "            false_negative.append(index)\n",
    "    else:\n",
    "        if pred == 0:\n",
    "            true_negative.append(index)\n",
    "        else:\n",
    "            true_positive.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(false_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_df = save_df_3[save_df_3.index.isin(false_positive)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_df = save_df_3[save_df_3.index.isin(true_negative)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "axes[0].title.set_text('False Positive')\n",
    "axes[1].title.set_text('True Negative')\n",
    "fp_df.sub_grade.sort_values().hist(ax=axes[0])\n",
    "tn_df.sub_grade.sort_values().hist(ax=axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "axes[0].title.set_text('False Positive')\n",
    "axes[1].title.set_text('True Negative')\n",
    "fp_df.addr_state.sort_values().hist(ax=axes[0])\n",
    "tn_df.addr_state.sort_values().hist(ax=axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_df.annual_inc.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_df.annual_inc.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "axes[0].title.set_text('False Positive')\n",
    "axes[1].title.set_text('True Negative')\n",
    "fp_df.annual_inc.sort_values().plot.box(ax=axes[0])\n",
    "tn_df.annual_inc.sort_values().plot.box(ax=axes[1])"
   ]
  }
 ]
}