{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('python3.8.8': conda)",
   "metadata": {
    "interpreter": {
     "hash": "36bf2d6b56364c7c2f7e9b6c8cc450b46f575ae98c5d77929445b306ba8812fb"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the packages that we need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "import coiled\n",
    "import joblib\n",
    "from joblib import dump, load\n",
    "pd.set_option('display.max_rows', 500)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dask_ml.preprocessing import Categorizer, DummyEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NAs\n",
    "def remove_na(dd):\n",
    "    \"\"\"\n",
    "    This function removes NAs and outliers in annual_inc\n",
    "\n",
    "    params: dd - a dask dataframe\n",
    "    returns: dd - a dask dataframe with only grades we need\n",
    "    \"\"\"\n",
    "    dd = dd.dropna(subset=['annual_inc',\n",
    "                            'dti',\n",
    "                            'pub_rec',\n",
    "                            'pub_rec_bankruptcies',\n",
    "                            'int_rate',\n",
    "                            'loan_amnt',\n",
    "                            'grade',\n",
    "                            'sub_grade',\n",
    "                            'verification_status',\n",
    "                            'term'\n",
    "                            ])\n",
    "    dd.annual_inc = dd.annual_inc[dd.annual_inc < 2e7]\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter out grades F and G\n",
    "def filter_grade(dd):\n",
    "    \"\"\"\n",
    "    This function filters out functions F and G\n",
    "\n",
    "    params: dd - a dask dataframe\n",
    "    returns: dd - a dask dataframe with only grades we need\n",
    "    \"\"\"\n",
    "    dd = dd[dd['grade'].isin(['A', 'B', 'C', 'D', 'E'])]\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_loan_status(dd):\n",
    "    dd = dd[dd['loan_status'].isin(['Charged Off','Fully Paid'])]\n",
    "\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineer days_since_earliest_credit\n",
    "def get_days_first_credit(dd):\n",
    "    \"\"\"\n",
    "    This function adds a new column that holds info on how many days has it been since first credit to loan issuance.\n",
    "\n",
    "    params: dd - a dask dataframe\n",
    "    returns: dd - a dask dataframe with the new column added\n",
    "    \"\"\"\n",
    "    dd['days_since_first_credit'] = (dd['issue_d'] - dd['earliest_cr_line']).dt.days\n",
    "    \n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean emp_length\n",
    "def clean_emp_length(dd):\n",
    "    \"\"\"\n",
    "    This function cleans emp_length\n",
    "\n",
    "    params: dd - a dask dataframe\n",
    "    returns: dd - a dask dataframe with the new column added\n",
    "    \"\"\"\n",
    "    dd.emp_length = dd.emp_length.replace(to_replace='< 1 year', value='0')\n",
    "    dd.emp_length = dd.emp_length.str.strip('<+ years')\n",
    "    dd.emp_length = dd.emp_length.fillna('-1')\n",
    "    dd.emp_length = dd.emp_length.astype(int)\n",
    "\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to separate data by term\n",
    "def separate_by_term(dd):\n",
    "    dd.term = dd.term.str.strip(' months').astype(int)\n",
    "     \n",
    "    df_3 = dd[dd.term == 36]\n",
    "    df_5 = dd[dd.term == 60]\n",
    "\n",
    "    df_3 = df_3[df_3['issue_d'].dt.year <= 2015]\n",
    "    df_5 = df_5[df_5['issue_d'].dt.year <= 2013]\n",
    "\n",
    "    return df_3,df_5  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to select all the features that we want\n",
    "def select_features(dd):\n",
    "    \"\"\"\n",
    "    This function selects only the features that we want for future modelling\n",
    "\n",
    "    params: dd - a dask dataframe\n",
    "    returns: dd - a dask dataframe with only the features selected\n",
    "\n",
    "    Notes:\n",
    "    1. We are not selecting grade since the information is already present in sub_grade\n",
    "    2. We are not selecting open_acc since we believe that feature is updated throughout time\n",
    "    3. Emp_title is dropped since we cannot clean it\n",
    "    4. Zip code is dropped since there is too many and State would give enough information\n",
    "    \"\"\"\n",
    "    dd = dd[[\n",
    "            'addr_state', # Need to dummify\n",
    "            'annual_inc',\n",
    "            'disbursement_method', # Need to binarize\n",
    "            'dti',\n",
    "            'emp_length', # Need to convert to number and add NAs\n",
    "            'fico_range_high', \n",
    "            'fico_range_low',\n",
    "            'home_ownership', # Need to dummify\n",
    "            'initial_list_status', # Need to dummify (binarize)\n",
    "            'installment',\n",
    "            'int_rate',\n",
    "            'loan_amnt', \n",
    "            'pub_rec', \n",
    "            'pub_rec_bankruptcies',\n",
    "            'purpose', # Need to dummify\n",
    "            'sub_grade', # Need to dummify or be ordinal encoded\n",
    "            'verification_status',\n",
    "            'loan_status' # Need to dummify\n",
    "    ]]\n",
    "\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical(dd):\n",
    "    ce = Categorizer(columns=['addr_state', 'disbursement_method', 'emp_length', 'home_ownership', 'initial_list_status', 'purpose', 'verification_status', 'sub_grade'])\n",
    "    dd = ce.fit_transform(dd)\n",
    "    de = DummyEncoder(columns=['addr_state', 'disbursement_method', 'emp_length', 'home_ownership', 'initial_list_status', 'purpose', 'verification_status', 'sub_grade'])\n",
    "    dd = de.fit_transform(dd)\n",
    "\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(dd):\n",
    "    scaler = StandardScaler()\n",
    "    dd = scaler.fit_transform(dd)\n",
    "\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Output()",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bc05759b133640b282deb0ea1fa4c979"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<rich.jupyter.JupyterRenderable at 0x7f7f4b310e80>",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dashboard: http://ec2-3-139-97-249.us-east-2.compute.amazonaws.com:8787\n"
     ]
    }
   ],
   "source": [
    "cluster = coiled.Cluster(n_workers=10)\n",
    "# cluster = coiled.Cluster(name='DarishSakeesing-bc650b6e-1')\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "print('Dashboard:', client.dashboard_link)\n",
    "\n",
    "\n",
    "\n",
    "raw_data = dd.read_csv(\n",
    "    \"s3://lending-club/accepted_2007_to_2018Q4.csv\",\n",
    "    dtype={'desc': 'object', \n",
    "            'id': 'object',\n",
    "            'sec_app_earliest_cr_line': 'object'}, \n",
    "    parse_dates = ['issue_d','earliest_cr_line'],\n",
    "    low_memory=False,\n",
    "    storage_options={\"anon\": True},\n",
    "    blocksize=\"16 MiB\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = remove_na(raw_data)\n",
    "raw_data = filter_grade(raw_data)\n",
    "raw_data = filter_loan_status(raw_data)\n",
    "raw_data = get_days_first_credit(raw_data)\n",
    "raw_data = clean_emp_length(raw_data)\n",
    "df_3, df_5 = separate_by_term(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = select_features(df_3)\n",
    "df_5 = select_features(df_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_3 = df_3.pop('loan_status')\n",
    "y_5 = df_5.pop('loan_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = encode_categorical(df_3)\n",
    "df_5 = encode_categorical(df_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = scale_features(df_3)\n",
    "df_5 = scale_features(df_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_3 = LabelEncoder()\n",
    "y_3 = le_3.fit_transform(y_3)\n",
    "le_5 = LabelEncoder()\n",
    "y_5 = le_5.fit_transform(y_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with joblib.parallel_backend('dask', n_jobs=-1):\n",
    "    X_3_train, X_3_test, y_3_train, y_3_test = train_test_split(df_3.compute(), y_3.compute(), test_size=0.2, shuffle=True)\n",
    "    X_5_train, X_5_test, y_5_train, y_5_test = train_test_split(df_5.compute(), y_5.compute(), test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_scoring(estimator, X, y):\n",
    "    return roc_auc_score(y, estimator.predict(X), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constucting Priors List\n",
    "priors = []\n",
    "for x in range(0, 101, 1):\n",
    "    priors.append([x/100, (100-x)/100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Initialized estimators\n",
      "Initialized grid\n",
      "Entered parallel backend\n",
      "Fitting 3 folds for each of 101 candidates, totalling 303 fits\n",
      "Finished 3, Starting 5\n",
      "Fitting 3 folds for each of 101 candidates, totalling 303 fits\n"
     ]
    }
   ],
   "source": [
    "params = {'priors': priors}\n",
    "lda_3 = LinearDiscriminantAnalysis()\n",
    "lda_5 = LinearDiscriminantAnalysis()\n",
    "print('Initialized estimators')\n",
    "\n",
    "\n",
    "grid_search_3 = GridSearchCV(estimator=lda_3, param_grid=params, scoring=custom_scoring, n_jobs=-1, cv=3, verbose=5)\n",
    "grid_search_5 = GridSearchCV(estimator=lda_5, param_grid=params, scoring=custom_scoring, n_jobs=-1, cv=3, verbose=5)\n",
    "print('Initialized grid')\n",
    "\n",
    "with joblib.parallel_backend('dask', n_jobs=-1, scatter=[X_3_train, y_3_train, X_5_train, y_5_train]):\n",
    "    print('Entered parallel backend')\n",
    "    grid_search_3.fit(X_3_train, y_3_train)\n",
    "    print('Finished 3, Starting 5')\n",
    "    grid_search_5.fit(X_5_train, y_5_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_3 = LinearDiscriminantAnalysis(priors=grid_search_3.best_params_['priors'])\n",
    "lda_3.fit(X_3_train, y_3_train)\n",
    "cm_3 = confusion_matrix(y_3_test, lda_3.predict(X_3_test), labels=[0,1])\n",
    "cm_3_df = pd.DataFrame(cm_3, columns=[f'Pred_{label}' for label in le_3.classes_.compute()], index= [f'True_{label}' for label in le_3.classes_.compute()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_5 = LinearDiscriminantAnalysis(priors=grid_search_5.best_params_['priors'])\n",
    "lda_5.fit(X_5_train, y_5_train)\n",
    "cm_5 = confusion_matrix(y_5_test, lda_5.predict(X_5_test), labels=[0,1])\n",
    "cm_5_df = pd.DataFrame(cm_5, columns=[f'Pred_{label}' for label in le_5.classes_.compute()], index= [f'True_{label}' for label in le_5.classes_.compute()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  Pred_Charged Off  Pred_Fully Paid\n",
       "True_Charged Off              9984             6905\n",
       "True_Fully Paid              35896            69839"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pred_Charged Off</th>\n      <th>Pred_Fully Paid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>True_Charged Off</th>\n      <td>9984</td>\n      <td>6905</td>\n    </tr>\n    <tr>\n      <th>True_Fully Paid</th>\n      <td>35896</td>\n      <td>69839</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "cm_3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  Pred_Charged Off  Pred_Fully Paid\n",
       "True_Charged Off               703             1539\n",
       "True_Fully Paid               1413             5902"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pred_Charged Off</th>\n      <th>Pred_Fully Paid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>True_Charged Off</th>\n      <td>703</td>\n      <td>1539</td>\n    </tr>\n    <tr>\n      <th>True_Fully Paid</th>\n      <td>1413</td>\n      <td>5902</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "cm_5_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}