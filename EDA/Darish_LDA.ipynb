{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import dask.dataframe as dd\n",
    "from dask_ml.preprocessing import OneHotEncoder, DummyEncoder, Categorizer, LabelEncoder, StandardScaler\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "approved_data = dd.read_csv('../data/approved1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "id                        int64\n",
       "addr_state               object\n",
       "annual_inc              float64\n",
       "application_type         object\n",
       "disbursement_method      object\n",
       "dti                     float64\n",
       "earliest_cr_line         object\n",
       "emp_length               object\n",
       "emp_title                object\n",
       "fico_range_high         float64\n",
       "fico_range_low          float64\n",
       "grade                    object\n",
       "home_ownership           object\n",
       "initial_list_status      object\n",
       "installment             float64\n",
       "int_rate                float64\n",
       "issue_d                  object\n",
       "loan_amnt               float64\n",
       "open_acc                float64\n",
       "pub_rec                 float64\n",
       "pub_rec_bankruptcies    float64\n",
       "purpose                  object\n",
       "sub_grade                object\n",
       "term                     object\n",
       "verification_status      object\n",
       "zip_code                 object\n",
       "loan_status              object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "approved_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of missing in id\n",
    "# print('Number of missing in addr_state: ', approved_data.addr_state.isna().sum().compute())\n",
    "# print('Number of missing in annual_inc: ', approved_data.annual_inc.isna().sum().compute())\n",
    "# print('Number of missing in disbursement_method: ', approved_data.disbursement_method.isna().sum().compute())\n",
    "# print('Number of missing in dti: ', approved_data.dti.isna().sum().compute())\n",
    "# print('Number of missing in earliest_cr_line: ', approved_data.earliest_cr_line.isna().sum().compute())\n",
    "# print('Number of missing in emp_length: ', approved_data.emp_length.isna().sum().compute())\n",
    "# print('Number of missing in fico_range_low: ', approved_data.fico_range_low.isna().sum().compute())\n",
    "# print('Number of missing in fico_range_high: ', approved_data.fico_range_high.isna().sum().compute())\n",
    "# print('Number of missing in grade: ', approved_data.grade.isna().sum().compute())\n",
    "# print('Number of missing in home_ownership: ', approved_data.home_ownership.isna().sum().compute())\n",
    "# print('Number of missing in initial_list_status: ', approved_data.initial_list_status.isna().sum().compute())\n",
    "# print('Number of missing in installment: ', approved_data.installment.isna().sum().compute())\n",
    "# print('Number of missing in int_rate: ', approved_data.int_rate.isna().sum().compute())\n",
    "# print('Number of missing in issue_d: ', approved_data.issue_d.isna().sum().compute())\n",
    "# print('Number of missing in loan_amnt: ', approved_data.loan_amnt.isna().sum().compute())\n",
    "# print('Number of missing in open_acc: ', approved_data.open_acc.isna().sum().compute())\n",
    "# print('Number of missing in pub_rec: ', approved_data.pub_rec.isna().sum().compute())\n",
    "# print('Number of missing in pub_rec_bankruptcies: ', approved_data.pub_rec_bankruptcies.isna().sum().compute())\n",
    "# print('Number of missing in purpose: ', approved_data.purpose.isna().sum().compute())\n",
    "# print('Number of missing in sub_grade: ', approved_data.sub_grade.isna().sum().compute())\n",
    "# print('Number of missing in term: ', approved_data.term.isna().sum().compute())\n",
    "# print('Number of missing in verification_status: ', approved_data.verification_status.isna().sum().compute())\n",
    "# print('Number of missing in zip_code: ', approved_data.zip_code.isna().sum().compute())\n",
    "# print('Number of missing in loan_status: ', approved_data.loan_status.isna().sum().compute())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of rows in the data:  1303083\n"
     ]
    }
   ],
   "source": [
    "# print('Number of rows in the data: ', len(approved_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean emp_length\n",
    "approved_data.emp_length = approved_data.emp_length.replace(to_replace='< 1 year', value='0')\n",
    "approved_data.emp_length = approved_data.emp_length.str.strip('<+ years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_emp_length = np.floor(approved_data.emp_length.dropna().astype(int).mean())\n",
    "approved_data.emp_length = approved_data.emp_length.fillna(mean_emp_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "approved_data.emp_length = approved_data.emp_length.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate target from features\n",
    "y = approved_data.loan_status\n",
    "X = approved_data[['addr_state', 'annual_inc', 'application_type', 'disbursement_method', 'dti', 'earliest_cr_line', 'emp_length', 'fico_range_high', 'fico_range_low', 'grade',\n",
    "'home_ownership', 'initial_list_status', 'installment', 'int_rate', 'issue_d', 'loan_amnt', 'open_acc', 'pub_rec', 'pub_rec_bankruptcies', 'purpose', 'sub_grade', 'term', 'verification_status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace earliest_cr_line with number of days from earliest cr open to issue date\n",
    "X.earliest_cr_line = X.earliest_cr_line.map_partitions(pd.to_datetime, meta=('earliest_cr_line', 'datetime64[ns]'))\n",
    "X.issue_d = X.issue_d.map_partitions(pd.to_datetime, meta=('issue_d', 'datetime64[ns]'))\n",
    "X['days_since_first_credit'] = (X.issue_d - X.earliest_cr_line).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop earliest_cr_line and issue_d\n",
    "X = X.drop(['earliest_cr_line', 'issue_d', 'grade'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10    428296\n",
       "5     157584\n",
       "2     117971\n",
       "0     104722\n",
       "3     104288\n",
       "1      85753\n",
       "4      78078\n",
       "6      60675\n",
       "8      58718\n",
       "7      57675\n",
       "9      49323\n",
       "Name: emp_length, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "approved_data.emp_length.value_counts().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "approved_data.annual_inc = approved_data.annual_inc[approved_data.annual_inc < 2e7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = Categorizer(columns=['addr_state', 'application_type', 'disbursement_method', 'emp_length', 'home_ownership', 'initial_list_status', 'purpose', 'term', 'verification_status', 'sub_grade'])\n",
    "X = ce.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "de = DummyEncoder(columns=['addr_state', 'application_type', 'disbursement_method', 'emp_length', 'home_ownership', 'initial_list_status', 'purpose', 'term', 'verification_status', 'sub_grade'])\n",
    "X = de.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "y.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['Charged Off', 'Fully Paid'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "le.classes_.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.80756436, 0.80954811, 0.81030785, 0.80480861, 0.80368818])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "cross_val_score(lda, X.compute(), y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/darishsakeesing/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/__init__.py:181: PerformanceWarning: Slicing with an out-of-order index is generating 160253 times more chunks\n",
      "  return array[key] if axis == 0 else array[:, key]\n",
      "/Users/darishsakeesing/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/__init__.py:181: PerformanceWarning: Slicing with an out-of-order index is generating 40061 times more chunks\n",
      "  return array[key] if axis == 0 else array[:, key]\n"
     ]
    }
   ],
   "source": [
    "lda1 = LinearDiscriminantAnalysis(priors=[count_0, count_1])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.compute(), y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_1 = y.sum() / len(y)\n",
    "count_0 = 1 - count_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda1.fit(X_train, y_train)\n",
    "probs_positive_class = lda1.predict_proba(X_test)[:, 1]\n",
    "prediction = probs_positive_class > .9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 45611,   4385],\n",
       "       [149796,  60825]])"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "confusion_matrix(y_test, prediction, labels=[0, 1])"
   ]
  }
 ]
}