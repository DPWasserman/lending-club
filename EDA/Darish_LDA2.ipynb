{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('python3.8.8': conda)",
   "metadata": {
    "interpreter": {
     "hash": "36bf2d6b56364c7c2f7e9b6c8cc450b46f575ae98c5d77929445b306ba8812fb"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Output()",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d26de339dda044af9a97b87425ff76cc"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<rich.jupyter.JupyterRenderable at 0x7ffe27fa9070>",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Using existing cluster: <span style=\"color: #008000; text-decoration-color: #008000\">'DarishSakeesing-a0202bf8-9'</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<rich.jupyter.JupyterRenderable at 0x7ffe27fb54f0>",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dashboard: http://ec2-3-142-225-170.us-east-2.compute.amazonaws.com:8787\n"
     ]
    }
   ],
   "source": [
    "# to reconnect to the cluster\n",
    "import coiled\n",
    "# cluster = coiled.Cluster(name='DarishSakeesing-e2b407d7-f')\n",
    "cluster = coiled.Cluster(name='DarishSakeesing-a0202bf8-9')\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "print('Dashboard:', client.dashboard_link)from dask_ml.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "raw_data = dd.read_csv(\n",
    "    \"s3://lending-club/accepted_2007_to_2018Q4.csv\",\n",
    "    dtype={'desc': 'object', \n",
    "            'id': 'object',\n",
    "            'sec_app_earliest_cr_line': 'object'}, \n",
    "    parse_dates = ['issue_d','earliest_cr_line'],\n",
    "    low_memory=False,\n",
    "    storage_options={\"anon\": True},\n",
    "    blocksize=\"16 MiB\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out the relavant features\n",
    "raw_data = raw_data[['id',\n",
    "                     'addr_state', # Need to dummify\n",
    "                     'annual_inc',\n",
    "                     'application_type', # Need to binarize \n",
    "                     'disbursement_method', # Need to binarize\n",
    "                     'dti',\n",
    "                     'earliest_cr_line',\n",
    "                     'emp_length', # Need to convert to number and add NAs\n",
    "                     'emp_title', # Needs to be encoded\n",
    "                     'fico_range_high', \n",
    "                     'fico_range_low',\n",
    "                     'grade', # Need to dummify or be ordinal encoded\n",
    "                     'home_ownership', # Need to dummify\n",
    "                     'initial_list_status', # Need to dummify (binarize)\n",
    "                     'installment',\n",
    "                     'int_rate',\n",
    "                     'issue_d',\n",
    "                     'loan_amnt',\n",
    "                     'open_acc', \n",
    "                     'pub_rec', \n",
    "                     'pub_rec_bankruptcies',\n",
    "                     'purpose', # Need to dummify\n",
    "                     'sub_grade', # Need to dummify or be ordinal encoded\n",
    "                     'term', # Need to convert to integer from string\n",
    "                     'verification_status',\n",
    "                     'zip_code',\n",
    "                     'loan_status' # Need to dummify\n",
    "                    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the values in the term column\n",
    "\n",
    "#print('Values in term \\n', raw_data.term.unique().compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the observation with NAs in the term columns, then convert term to integer\n",
    "raw_data = raw_data.dropna(subset=['term'])\n",
    "\n",
    "raw_data.term = raw_data.term.str.strip(' months').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate 36 and 60 months loans\n",
    "df_3 = raw_data[raw_data.term == 36]\n",
    "df_5 = raw_data[raw_data.term == 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only consider loans that are either charged off or fully paid\n",
    "df_3 = df_3[df_3['loan_status'].isin(['Charged Off','Fully Paid'])]\n",
    "df_5 = df_5[df_5['loan_status'].isin(['Charged Off','Fully Paid'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are NAs in the issue_d field\n",
    "# print('NAs in issue_d among 3-year loans:', sum(df_3.issue_d.isna()))\n",
    "# print('NAs in issue_d among 5-year loans:', sum(df_5.issue_d.isna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop application_type column\n",
    "df_3 = df_3.drop(['application_type', 'term', 'open_acc'], axis=1)\n",
    "df_5 = df_5.drop(['application_type', 'term', 'open_acc'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at only a subset of years for each loan term\n",
    "df_3 = df_3[df_3['issue_d'].dt.year <= 2015]\n",
    "df_5 = df_5[df_5['issue_d'].dt.year <= 2013]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop obs that have NAs in those columns because they are probably bad observations\n",
    "\n",
    "df_3 = df_3.dropna(subset=['annual_inc',\n",
    "                              'dti',\n",
    "                              'pub_rec',\n",
    "                              'pub_rec_bankruptcies',\n",
    "                              'int_rate',\n",
    "                              'loan_amnt',\n",
    "                              'grade',\n",
    "                              'sub_grade',\n",
    "                              'verification_status'\n",
    "                              ])\n",
    "df_5 = df_5.dropna(subset=['annual_inc',\n",
    "                              'dti',\n",
    "                              'pub_rec',\n",
    "                              'pub_rec_bankruptcies',\n",
    "                              'int_rate',\n",
    "                              'loan_amnt',\n",
    "                              'grade',\n",
    "                              'sub_grade',\n",
    "                              'verification_status'\n",
    "                              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the type columns\n",
    "# print(df_3.dtypes)\n",
    "# print(df_5.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature that calculates the number of days between earliest credit line and issue_d\n",
    "df_3['days_since_first_credit'] = (df_3['issue_d'] - df_3['earliest_cr_line']).dt.days\n",
    "df_5['days_since_first_credit'] = (df_5['issue_d'] - df_5['earliest_cr_line']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop earliest_cr_line and issue_d\n",
    "df_3 = df_3.drop(['earliest_cr_line', 'issue_d'], axis=1)\n",
    "df_5 = df_5.drop(['earliest_cr_line', 'issue_d'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any remaining NAs in all the columns\n",
    "# Takes a long time to run (maybe i am not using the full potential of clusters, use map_partitions?)\n",
    "\n",
    "# print('===== 3 YEAR LOANS =====')\n",
    "# for col in df_3.columns:\n",
    "#     print(f'NAs in {col}:', sum(df_3[col].isna()))\n",
    "# print('===== 5 YEAR LOANS =====')\n",
    "# for col in df_5.columns:\n",
    "#     print(f'NAs in {col}:', sum(df_5[col].isna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean emp_length\n",
    "import dask.array as da\n",
    "\n",
    "## 3 YEARS\n",
    "df_3.emp_length = df_3.emp_length.replace(to_replace='< 1 year', value='0')\n",
    "df_3.emp_length = df_3.emp_length.str.strip('<+ years')\n",
    "\n",
    "mean_emp_length_3 = da.floor(df_3.emp_length.dropna().astype(int).mean())\n",
    "df_3.emp_length = df_3.emp_length.fillna(mean_emp_length_3)\n",
    "df_3.emp_length = df_3.emp_length.astype(int)\n",
    "\n",
    "## 5 YEARS\n",
    "df_5.emp_length = df_5.emp_length.replace(to_replace='< 1 year', value='0')\n",
    "df_5.emp_length = df_5.emp_length.str.strip('<+ years')\n",
    "\n",
    "mean_emp_length_5 = da.floor(df_5.emp_length.dropna().astype(int).mean())\n",
    "df_5.emp_length = df_5.emp_length.fillna(mean_emp_length_5)\n",
    "df_5.emp_length = df_5.emp_length.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the different values in loan_status\n",
    "\n",
    "# print('Values in loan_status (3 years): \\n', df_3.loan_status.unique().compute())\n",
    "# print('Values in loan_status (5 years): \\n', df_5.loan_status.unique().compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only consider grade A, B, C, D, E\n",
    "df_3 = df_3[df_3['grade'].isin(['A', 'B', 'C', 'D', 'E'])]\n",
    "df_5 = df_5[df_5['grade'].isin(['A', 'B', 'C', 'D', 'E'])]\n",
    "\n",
    "# drop grade and emp_titlte after that\n",
    "df_3 = df_3.drop(['grade', 'emp_title'], axis=1)\n",
    "df_5 = df_5.drop(['grade','emp_title'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers in annual_inc\n",
    "df_3.annual_inc = df_3.annual_inc[df_3.annual_inc < 2e7]\n",
    "df_5.annual_inc = df_5.annual_inc[df_5.annual_inc < 2e7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate target and features\n",
    "y_3 = df_3.loan_status\n",
    "X_3 = df_3[['addr_state', 'annual_inc', 'disbursement_method', 'dti', 'emp_length', 'fico_range_high', 'fico_range_low', 'home_ownership', 'initial_list_status', 'installment', 'int_rate', 'loan_amnt', 'pub_rec', 'pub_rec_bankruptcies', 'purpose', 'sub_grade', 'verification_status', 'days_since_first_credit']]\n",
    "\n",
    "y_5 = df_5.loan_status\n",
    "X_5 = df_5[['addr_state', 'annual_inc', 'disbursement_method', 'dti', 'emp_length', 'fico_range_high', 'fico_range_low', 'home_ownership', 'initial_list_status', 'installment', 'int_rate', 'loan_amnt', 'pub_rec', 'pub_rec_bankruptcies', 'purpose', 'sub_grade', 'verification_status', 'days_since_first_credit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy encode categorical variables in X\n",
    "from dask_ml.preprocessing import Categorizer, DummyEncoder, LabelEncoder\n",
    "\n",
    "ce_3 = Categorizer(columns=['addr_state', 'disbursement_method', 'emp_length', 'home_ownership', 'initial_list_status', 'purpose', 'verification_status', 'sub_grade'])\n",
    "X_3 = ce_3.fit_transform(X_3)\n",
    "ce_5 = Categorizer(columns=['addr_state', 'disbursement_method', 'emp_length', 'home_ownership', 'initial_list_status', 'purpose', 'verification_status', 'sub_grade'])\n",
    "X_5 = ce_5.fit_transform(X_5)\n",
    "\n",
    "de_3 = DummyEncoder(columns=['addr_state', 'disbursement_method', 'emp_length', 'home_ownership', 'initial_list_status', 'purpose', 'verification_status', 'sub_grade'])\n",
    "X_3 = de_3.fit_transform(X_3)\n",
    "de_5 = DummyEncoder(columns=['addr_state', 'disbursement_method', 'emp_length', 'home_ownership', 'initial_list_status', 'purpose', 'verification_status', 'sub_grade'])\n",
    "X_5 = de_5.fit_transform(X_5)\n",
    "\n",
    "# Label Encode target variable\n",
    "le_3 = LabelEncoder()\n",
    "y_3 = le_3.fit_transform(y_3)\n",
    "le_5 = LabelEncoder()\n",
    "y_5 = le_5.fit_transform(y_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "from dask_ml.preprocessing import StandardScaler\n",
    "scaler_3 = StandardScaler()\n",
    "X_3 = scaler_3.fit_transform(X_3)\n",
    "\n",
    "scaler_5 = StandardScaler()\n",
    "X_5 = scaler_5.fit_transform(X_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "annual_inc         float64\n",
      "dti                float64\n",
      "fico_range_high    float64\n",
      "fico_range_low     float64\n",
      "installment        float64\n",
      "                    ...   \n",
      "sub_grade_E5       float64\n",
      "sub_grade_A3       float64\n",
      "sub_grade_D5       float64\n",
      "sub_grade_E2       float64\n",
      "sub_grade_E4       float64\n",
      "Length: 123, dtype: object\n",
      "annual_inc         float64\n",
      "dti                float64\n",
      "fico_range_high    float64\n",
      "fico_range_low     float64\n",
      "installment        float64\n",
      "                    ...   \n",
      "sub_grade_E5       float64\n",
      "sub_grade_A3       float64\n",
      "sub_grade_D5       float64\n",
      "sub_grade_E2       float64\n",
      "sub_grade_E4       float64\n",
      "Length: 123, dtype: object\n",
      "[0 1]\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(X_3.dtypes)\n",
    "print(X_3.dtypes)\n",
    "print(da.unique(y_3).compute())\n",
    "print(da.unique(y_5).compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train_test_split\n",
    "from dask_ml.model_selection import train_test_split\n",
    "\n",
    "X_3_train, X_3_test, y_3_train, y_3_test = train_test_split(X_3, y_3, test_size=0.2, shuffle=True, convert_mixed_types=True)\n",
    "X_5_train, X_5_test, y_5_train, y_5_test = train_test_split(X_5, y_5, test_size=0.2, shuffle=True, convert_mixed_types=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constructing priors list\n",
    "priors = []\n",
    "for x in range(0, 101, 1):\n",
    "    priors.append([x/100, (100-x)/100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def custom_scoring(estimator, X, y):\n",
    "    cm = confusion_matrix(y, estimator.predict(X))\n",
    "    score = 0.7*(cm[0, 1]) + 0.3*(cm[1, 0])\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'priors': priors}\n",
    "lda_3 = LinearDiscriminantAnalysis()\n",
    "lda_5 = LinearDiscriminantAnalysis()\n",
    "\n",
    "grid_search_3 = GridSearchCV(estimator=lda_3, param_grid=params, scoring='balanced_accuracy', n_jobs=-1, cv=3, verbose=3)\n",
    "grid_search_5 = GridSearchCV(estimator=lda_5, param_grid=params, scoring='balanced_accuracy', n_jobs=-1, cv=3, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'dask.array.core.Array'>\n<class 'dask.array.core.Array'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_3_train))\n",
    "print(type(y_3_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fully Paid     528884\n",
      "Charged Off     84236\n",
      "Name: loan_status, dtype: int64\n",
      "Fully Paid     36525\n",
      "Charged Off    11258\n",
      "Name: loan_status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_3.loan_status.value_counts().compute()) \n",
    "print(df_5.loan_status.value_counts().compute())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_3 = X_3.compute()\n",
    "# X_5 = X_5.compute()\n",
    "# y_3 = y_3.compute()\n",
    "y_5 = y_5.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3_train, X_3_test, y_3_train, y_3_test = sktt(X_3, y_3, test_size=0.2, shuffle=True)\n",
    "X_5_train, X_5_test, y_5_train, y_5_test = sktt(X_5, y_5, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 101 candidates, totalling 303 fits\n",
      "Fitting 3 folds for each of 101 candidates, totalling 303 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split as sktt\n",
    "with joblib.parallel_backend('dask', n_jobs=-1, scatter=[X_3_train, y_3_train]):\n",
    "    grid_search_3.fit(X_3_train, y_3_train)\n",
    "    grid_search_5.fit(X_5_train, y_5_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results_3 = pd.DataFrame(grid_search_3.cv_results_)\n",
    "results_5 = pd.DataFrame(grid_search_5.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "49      33.841194      0.608131          0.43325        0.029101   \n",
       "\n",
       "    param_priors                    params  split0_test_score  \\\n",
       "49  [0.49, 0.51]  {'priors': [0.49, 0.51]}           0.627287   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "49           0.625594           0.617491         0.623457        0.004275   \n",
       "\n",
       "    rank_test_score  \n",
       "49                1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_priors</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>49</th>\n      <td>33.841194</td>\n      <td>0.608131</td>\n      <td>0.43325</td>\n      <td>0.029101</td>\n      <td>[0.49, 0.51]</td>\n      <td>{'priors': [0.49, 0.51]}</td>\n      <td>0.627287</td>\n      <td>0.625594</td>\n      <td>0.617491</td>\n      <td>0.623457</td>\n      <td>0.004275</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "results_3[results_3['rank_test_score'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[10215,  6728],\n",
       "       [36417, 69264]])"
      ]
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "lda = LinearDiscriminantAnalysis(priors=[0.49, 0.51])\n",
    "lda.fit(X_3_train, y_3_train)\n",
    "confusion_matrix(y_3_test, lda.predict(X_3_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "47       1.957986      0.410794          0.26771         0.11056   \n",
       "\n",
       "    param_priors                    params  split0_test_score  \\\n",
       "47  [0.47, 0.53]  {'priors': [0.47, 0.53]}            0.57852   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "47           0.581386           0.552095         0.570667        0.013184   \n",
       "\n",
       "    rank_test_score  \n",
       "47                1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_priors</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>47</th>\n      <td>1.957986</td>\n      <td>0.410794</td>\n      <td>0.26771</td>\n      <td>0.11056</td>\n      <td>[0.47, 0.53]</td>\n      <td>{'priors': [0.47, 0.53]}</td>\n      <td>0.57852</td>\n      <td>0.581386</td>\n      <td>0.552095</td>\n      <td>0.570667</td>\n      <td>0.013184</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "results_5[results_5['rank_test_score'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1115, 1138],\n",
       "       [2455, 4849]])"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis(priors=[0.47, 0.53])\n",
    "lda.fit(X_5_train, y_5_train)\n",
    "confusion_matrix(y_5_test, lda.predict(X_5_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_3 = X_3.compute()\n",
    "# y_3 = y_3.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split as sktt\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# with joblib.parallel_backend('dask', n_jobs=-1):\n",
    "#     X_3_train, X_3_test, y_3_train, y_3_test = sktt(X_3, y_3, test_size=0.2, shuffle=True)\n",
    "#     logr = LogisticRegression()\n",
    "#     cross_val_score(estimator=logr, X=X_3, y=y_3, cv=3, n_jobs=-1, scoring='balanced_accuracy', verbose=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}